---
bg: "tools.jpg"
layout: post
title:  "A Walkthrough of Convolutional Neural Network"
crawlertitle: "Suki's Blog"
summary: "A Walkthrough of Convolutional Neural Network"
date:   2017-05-31 20:09:47 +0700
categories: posts
tags: ['deep-learning']
author: suki lau
---

Among the diverse deep learning architecture, convolutional neural network (convnets for short) stands out for its revoltionary performance on computer vision and have been extended to many other applications. It is also in itself a very interesting artificial neural network inspired by the animal visual cortex and sucessfully applied to vision recognition tasks.

In this article, I will provide a walkthrough on how to construct a convnet for simple visual recognition tasks, how to tune hyper-parameters for convnet and how to visualize the hidden convolutional layers. 

## What is convnet?

At its most basic, convnet is a special kind of neural networks which contains at least one convolutional layer. A convolutional layer uses many identical copies of the same set of neurons (we also call them filters) on small regions of image data. A basic convent's structure include a convolutional layer which takes input data, local/global pooling layer, and a fully connected layer to output the classification labels. Convnets are usually applied to image data. In such case, an image is treated as a matrix of pixel values as input data.

To understand why convnet works well in computer vision, we first take a look at why a regular neural network fails to recognize images. In a regular neural network, we use the entire image to train the network. It works well for simple centered image but fails to recogonise image with more complex internel variation. Having more hidden layers to learn abstract features would help but it is rather impractical as we need far too many neurons to train and store in memory.

On the other hand, a convnet recognises an image at a deeper level by learning a small set of shared filters.A convnet tries to learn individual parts of objects, stored in individual neurons, and add them up to recognise larger object. In other words, a convnet somehow learn the content of the image and generalize better in more complex image recogniation. The advantage of using shared weights in the convolutional layer helps largely reduce the actual learning parameters while it can still express computationally large model. 

## Hyper-parameter tuning








## Visualization







#### References:
* [Understanding Convolutions](http://colah.github.io/posts/2014-07-Understanding-Convolutions/)
* [Convolutional Neural Networks: Architectures, Convolution / Pooling Layers](http://cs231n.github.io/convolutional-networks/)
* [Understanding and Visualizing Convolutional Neural Networks](http://cs231n.github.io/understanding-cnn/)
* [Convolutional Neural Networks (CNNs): An Illustrated Explanation](http://xrds.acm.org/blog/2016/06/convolutional-neural-networks-cnns-illustrated-explanation/)


* [](http://rishy.github.io/ml/2017/01/05/how-to-train-your-dnn/)

* [](https://ml4a.github.io/ml4a/convnets/)
* [Understanding and Visualizing Convolutional Neural Networks](http://cs231n.github.io/understanding-cnn/]
* [](https://medium.com/rants-on-machine-learning/smarter-parameter-sweeps-or-why-grid-search-is-plain-stupid-c17d97a0e881)
* [](https://ml4a.github.io/ml4a/convnets/)
* [](https://ml4a.github.io/ml4a/looking_inside_neural_nets/)
